## Overview

This project, inspired by the Deep Learning Specialization course series by Deeplearning.ai, contains my personal neural network implementation.
Coded in Python, **this project only uses Numpy** for numerical computation (**No Tensorflow, Keras, sklearn, etc.**). All elements of the neural network, such as the backward propogation algorithm, have been implmented from scratch.

## Features

The API includes the following features: 
- The ability to add as many layers as desired
- A variety of parameter intializations (Small random and Xavier)
- A variety of optimization procedures (Gradient Descent, Momentum, RMSProp, Adam)
- Dropout Regularization
- Batch Normalization
- Stochastic Gradient Descent, Batch Gradient Descent and Mini-Batch Gradient Descent
- Various activation functions (Tanh, Relu, Softmax, Sigmoid)
